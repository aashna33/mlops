{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSrabJgqUVD9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0889TNMZiuq",
        "outputId": "64fdd7c3-ed94-4366-c79e-76eeff525133"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1]), array([900, 100]))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X,y=make_classification(n_samples=1000, n_features=10, n_informative=2,n_redundant=8,\n",
        "                        weights=[0.9,0.1], flip_y=0, random_state=42)\n",
        "np.unique(y, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWF5bhCzIeZL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oEfecrdZ_9W"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.3, stratify=y , random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBRNi6EPaOdi"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28jsfj37a2Lc"
      },
      "outputs": [],
      "source": [
        "smt=SMOTETomek(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uuSi7E5a6EF",
        "outputId": "b4b31869-3970-4998-bd4a-621507916a31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1]), array([619, 619]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_res, y_train_res=smt.fit_resample(X_train, y_train)\n",
        "np.unique(y_train_res, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi4N_JpBbDYU"
      },
      "outputs": [],
      "source": [
        "models=[\n",
        "    (\n",
        "        \"Logistic Regression\",\n",
        "        {\"C\":1, \"solver\":\"liblinear\"},\n",
        "        LogisticRegression(),\n",
        "        (X_train, y_train),\n",
        "        (X_test, y_test)\n",
        "    ),\n",
        "    (\n",
        "        \"Random Forest\",\n",
        "        {\"n_estimators\":30, \"max_depth\":3},\n",
        "        RandomForestClassifier(),\n",
        "        (X_train, y_train),\n",
        "        (X_test, y_test)\n",
        "    ),\n",
        "    (\n",
        "        \"XGBClassifier\",\n",
        "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
        "        XGBClassifier(),\n",
        "        (X_train, y_train),\n",
        "        (X_test, y_test)\n",
        "    ),\n",
        "    (\n",
        "        \"XGBClassifier With SMOTE\",\n",
        "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
        "        XGBClassifier(),\n",
        "        (X_train_res, y_train_res),\n",
        "        (X_test, y_test)\n",
        "    )\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw4vhU65bnBe"
      },
      "outputs": [],
      "source": [
        "reports=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjmliGe-bqpl"
      },
      "outputs": [],
      "source": [
        "for model_name, params, model, train_set, test_set in models:\n",
        "  X_train = train_set[0]\n",
        "  y_train = train_set[1]\n",
        "  X_test = test_set[0]\n",
        "  y_test = test_set[1]\n",
        "\n",
        "  model.set_params(**params)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred=model.predict(X_test)\n",
        "  report=classification_report(y_test, y_pred, output_dict=True)\n",
        "  reports.append(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY-mJb_vdqH_"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import mlflow.xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O4b5Xazd9ao",
        "outputId": "60f2ceb7-0086-4c9d-83bd-a6069c3086b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/11 04:12:37 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection' does not exist. Creating a new experiment.\n",
            "2025/09/11 04:12:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "\u001b[31m2025/09/11 04:12:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Logistic Regression'.\n",
            "2025/09/11 04:12:48 WARNING mlflow.tracking._model_registry.fluent: Run with id ebca1e63d55c40d5a9a491115c4c4374 has no artifacts at artifact path 'model', registering model based on models:/m-6125aa3e494c4a19b1edc5d1c2f38f49 instead\n",
            "Created version '1' of model 'Logistic Regression'.\n",
            "2025/09/11 04:12:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model Logistic Regression registered successfully with run_id: ebca1e63d55c40d5a9a491115c4c4374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/11 04:12:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Random Forest'.\n",
            "2025/09/11 04:12:54 WARNING mlflow.tracking._model_registry.fluent: Run with id 1af3a8586aec409b81d121514dc15301 has no artifacts at artifact path 'model', registering model based on models:/m-c52b5b5962d94e8390781f30921d2438 instead\n",
            "Created version '1' of model 'Random Forest'.\n",
            "2025/09/11 04:12:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model Random Forest registered successfully with run_id: 1af3a8586aec409b81d121514dc15301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/11 04:12:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'XGBClassifier'.\n",
            "2025/09/11 04:12:58 WARNING mlflow.tracking._model_registry.fluent: Run with id 707b75949e6547b6b7f63f6f5e9ad6af has no artifacts at artifact path 'model', registering model based on models:/m-439d7f1f72a74047b7c1a6bb59b0f0e4 instead\n",
            "Created version '1' of model 'XGBClassifier'.\n",
            "2025/09/11 04:12:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model XGBClassifier registered successfully with run_id: 707b75949e6547b6b7f63f6f5e9ad6af\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/09/11 04:13:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'XGBClassifier With SMOTE'.\n",
            "2025/09/11 04:13:01 WARNING mlflow.tracking._model_registry.fluent: Run with id 19272b84f62f4a299c0dfc04114387c8 has no artifacts at artifact path 'model', registering model based on models:/m-4d84789eb56c49569168fa7469080326 instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model XGBClassifier With SMOTE registered successfully with run_id: 19272b84f62f4a299c0dfc04114387c8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created version '1' of model 'XGBClassifier With SMOTE'.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_experiment(\"Anomaly Detection\")\n",
        "# Optional: set your tracking URI if remote\n",
        "# mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "\n",
        "for i, element in enumerate(models):\n",
        "    model_name = element[0]\n",
        "    params = element[1]\n",
        "    model = element[2]\n",
        "    report = reports[i]\n",
        "\n",
        "    with mlflow.start_run(run_name=model_name) as run:\n",
        "        run_id = run.info.run_id\n",
        "\n",
        "        # Log parameters and metrics\n",
        "        mlflow.log_params(params)\n",
        "        mlflow.log_metrics({\n",
        "            'accuracy': report['accuracy'],\n",
        "            'recall_class_1': report['1']['recall'],\n",
        "            'recall_class_0': report['0']['recall'],\n",
        "            'f1_score_macro': report['macro avg']['f1-score']\n",
        "        })\n",
        "\n",
        "        # Log model\n",
        "        if \"XGB\" in model_name:\n",
        "            mlflow.xgboost.log_model(model, \"model\")\n",
        "        else:\n",
        "            mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "        # ✅ Register the model (inside the active run)\n",
        "        model_uri = f\"runs:/{run_id}/model\"\n",
        "        mlflow.register_model(model_uri=model_uri, name=model_name)\n",
        "\n",
        "        print(f\"✅ Model {model_name} registered successfully with run_id: {run_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfg5sqwveFLz",
        "outputId": "4fb997f1-2f4f-4cdd-d0c5-42eb9402cf93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Successfully registered model 'XGB-Smote'.\n",
            "2025/09/11 04:13:01 WARNING mlflow.tracking._model_registry.fluent: Run with id 19272b84f62f4a299c0dfc04114387c8 has no artifacts at artifact path 'model', registering model based on models:/m-4d84789eb56c49569168fa7469080326 instead\n",
            "Created version '1' of model 'XGB-Smote'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1757563981677, current_stage='None', deployment_job_state=None, description=None, last_updated_timestamp=1757563981677, metrics=[<Metric: dataset_digest=None, dataset_name=None, key='accuracy', model_id='m-4d84789eb56c49569168fa7469080326', run_id='19272b84f62f4a299c0dfc04114387c8', step=0, timestamp=1757563978345, value=0.9633333333333334>,\n",
              " <Metric: dataset_digest=None, dataset_name=None, key='f1_score_macro', model_id='m-4d84789eb56c49569168fa7469080326', run_id='19272b84f62f4a299c0dfc04114387c8', step=0, timestamp=1757563978345, value=0.8996319839411174>,\n",
              " <Metric: dataset_digest=None, dataset_name=None, key='recall_class_0', model_id='m-4d84789eb56c49569168fa7469080326', run_id='19272b84f62f4a299c0dfc04114387c8', step=0, timestamp=1757563978345, value=0.9777777777777777>,\n",
              " <Metric: dataset_digest=None, dataset_name=None, key='recall_class_1', model_id='m-4d84789eb56c49569168fa7469080326', run_id='19272b84f62f4a299c0dfc04114387c8', step=0, timestamp=1757563978345, value=0.8333333333333334>], model_id='m-4d84789eb56c49569168fa7469080326', name='XGB-Smote', params={'eval_metric': 'logloss', 'use_label_encoder': 'False'}, run_id='19272b84f62f4a299c0dfc04114387c8', run_link=None, source='models:/m-4d84789eb56c49569168fa7469080326', status='READY', status_message=None, tags={}, user_id=None, version=1>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.register_model(model_uri=f\"runs:/{run_id}/model\", name=\"XGB-Smote\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U4RWtMreKMw",
        "outputId": "72f0941a-e1c5-4efa-9f79-af3e57d02f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "import mlflow.xgboost\n",
        "\n",
        "model_name = \"XGB-Smote\"\n",
        "model_version = 1\n",
        "model_uri = f\"models:/{model_name}/{model_version}\"\n",
        "\n",
        "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
        "\n",
        "# Predict\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "print(y_pred[:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxJmYSvReMWF",
        "outputId": "1512f36a-6dd6-48f4-dafc-a92163a02031"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_version = 1\n",
        "model_uri = f\"models:/{model_name}/{model_version}\"\n",
        "\n",
        "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPznOwa6eOmQ",
        "outputId": "6f38b2df-4520-4b6a-f01c-8695d25e0d04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'anomaly-detection-prod' already exists. Creating a new version of this model...\n",
            "Copied version '1' of model 'XGB-Smote' to version '1' of model 'anomaly-detection-prod'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1757563981754, current_stage='None', deployment_job_state=None, description=None, last_updated_timestamp=1757563981754, metrics=None, model_id=None, name='anomaly-detection-prod', params=None, run_id='19272b84f62f4a299c0dfc04114387c8', run_link=None, source='models:/XGB-Smote/1', status='READY', status_message=None, tags={}, user_id=None, version=1>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "model_name = \"XGB-Smote\"\n",
        "production_model_name = \"anomaly-detection-prod\"\n",
        "source_version = 1\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# (Optional) set alias for clarity\n",
        "client.set_registered_model_alias(model_name, \"challenger\", version=source_version)\n",
        "\n",
        "# Make sure destination exists\n",
        "try:\n",
        "    client.create_registered_model(production_model_name)\n",
        "except Exception:\n",
        "    pass  # Already exists\n",
        "\n",
        "\n",
        "# Copy the version\n",
        "client.copy_model_version(\n",
        "    src_model_uri=f\"models:/{model_name}@challenger\",\n",
        "    dst_name=production_model_name\n",
        ")\n",
        "\n",
        "#client.set_registered_model_alias(production_model_name, \"champion\", new_version.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4JYfMAneQmX",
        "outputId": "9eeb0f51-0d59-474e-b6b0-aa4e3046540e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_version = 1\n",
        "prod_model_uri = f\"models:/{model_name}@challenger\"\n",
        "\n",
        "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnwQQ-NCeTbB",
        "outputId": "8a7ba7eb-fca9-4fdd-9c30-55a0e1ed2a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'anomaly-detection-prod' already exists. Creating a new version of this model...\n",
            "Copied version '1' of model 'XGB-Smote' to version '2' of model 'anomaly-detection-prod'.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Names and versions\n",
        "model_name = \"XGB-Smote\"                 # source registered model\n",
        "production_model_name = \"anomaly-detection-prod\"  # target registered model\n",
        "source_version = 1                       # source version to copy\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# (Optional) set alias on the source model for clarity\n",
        "client.set_registered_model_alias(model_name, \"challenger\", version=source_version)\n",
        "\n",
        "# Make sure destination registered model exists\n",
        "try:\n",
        "    client.create_registered_model(production_model_name)\n",
        "except Exception:\n",
        "    pass  # already exists\n",
        "\n",
        "# Copy challenger version into production registry\n",
        "new_version = client.copy_model_version(\n",
        "    src_model_uri=f\"models:/{model_name}@challenger\",\n",
        "    dst_name=production_model_name\n",
        ")\n",
        "\n",
        "# Assign alias 'champion' to the copied version\n",
        "client.set_registered_model_alias(\n",
        "    production_model_name, \"champion\", new_version.version\n",
        ")\n",
        "\n",
        "# Load the champion model\n",
        "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
        "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
        "\n",
        "# Run predictions\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "print(y_pred[:4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vegHf6PuihlP"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "import mlflow.pyfunc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWCNAD3AAQXY"
      },
      "outputs": [],
      "source": [
        "app=FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX2B4xKpAhPe"
      },
      "outputs": [],
      "source": [
        "model=mlflow.pyfunc.load_model(\"models:/anomaly-detection-prod@champion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV4SOEe6AquW"
      },
      "outputs": [],
      "source": [
        "@app.get(\"/\")\n",
        "def root():\n",
        "  return{\"message\": \"MLflow model is live!\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0T-8KvCA34c"
      },
      "outputs": [],
      "source": [
        "@app.post(\"/predict\")\n",
        "def predict(data: dict):\n",
        "  X=[list(data.values())]\n",
        "  y_pred=model.predict(X)\n",
        "  return {\"prediction\": y_pred.tolist()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_oAPy8ZBX-0"
      },
      "outputs": [],
      "source": [
        "#mlfow wraps the ml model, after wrapping it predicts output in json format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgcFrArRCWjY",
        "outputId": "bdc7e4e9-3d3f-4c43-c890-15dd297b888e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing serve.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile serve.py\n",
        "from fastapi import FastAPI\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "app=FastAPI()\n",
        "model=uri=\"models:/anomaly-detection-prod@champion\"\n",
        "model=mlflow.pyfunc.load_model(model_uri)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "  return{\"message\": \"mlflow model is live inside Docker!\"}\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(data: dict):\n",
        "  \"\"\"\n",
        "  Expects input like:\n",
        "  {\n",
        "    \"feature1\":0.5,\n",
        "    \"feature2\":1.2,\n",
        "    \"feature3\":-0.8\n",
        "\n",
        "  }\n",
        "  \"\"\"\n",
        "  df=pd.DataFrame([data])\n",
        "  prediction=model.predict(df)\n",
        "  return {\"prediction\": prediction.tolist()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "loAN5lbiGP--",
        "outputId": "261cf2df-f499-40e3-de33-bd12cb605065"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_22a04fd9-d070-4a5b-9e07-2ee53f623ae8\", \"serve.py\", 517)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoTx1CdhHAyV",
        "outputId": "af352df3-f6ac-4406-f684-83c243af7446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile Dockerfile\n",
        "#Base image with python\n",
        "FROM python:3.9\n",
        "\n",
        "#set working directory inside container\n",
        "WORKDIR /app\n",
        "\n",
        "#copy files\n",
        "COPY serve.py /app\n",
        "COPY requirements.txt /app\n",
        "\n",
        "#Install dependencies\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "#expose FASTAPI port\n",
        "EXPOSE 8000\n",
        "\n",
        "#start fastapi app\n",
        "CMD [\"uvicorn\", \"serve:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tT648d1xIxgK",
        "outputId": "7d7eab2e-8a15-4143-e3df-1bf4c4454b15"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b444d2f7-ab48-4f56-ac6a-0f68d3f01ca9\", \"Dockerfile\", 351)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "yFL00tViI878",
        "outputId": "f902ef6a-8cf8-4a49-cd31-7453fcba0bb0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n{\\n  \"builder\": {\\n    \"gc\": {\\n      \"defaultKeepStorage\": \"20GB\",\\n      \"enabled\": true\\n    }\\n  },\\n  \"experimental\": false,\\n  \"registry-mirrors\": [\\n    \"https://mirror.gcr.io\"\\n  ]\\n}\\n\\nthen pull ur python version \\ndocker pull python:3.10-slim\\n'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#docker engine code\n",
        "\"\"\"\n",
        "{\n",
        "  \"builder\": {\n",
        "    \"gc\": {\n",
        "      \"defaultKeepStorage\": \"20GB\",\n",
        "      \"enabled\": true\n",
        "    }\n",
        "  },\n",
        "  \"experimental\": false,\n",
        "  \"registry-mirrors\": [\n",
        "    \"https://mirror.gcr.io\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "then pull ur python version\n",
        "docker pull python:3.10-slim\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV1k6GU6S4pb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
